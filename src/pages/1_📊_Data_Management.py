import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
import plotly.express as px
import plotly.graph_objects as go
import json
from datetime import datetime
import os
from src.utils.rtl_utils import apply_arabic_config

# ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠ
apply_arabic_config(title="Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", icon="ğŸ“Š")

# ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù†Ù…Ø·
st.markdown("""
    <style>
    .main {
        padding: 0rem 1rem;
    }
    .stAlert {
        padding: 1rem;
        margin-bottom: 1rem;
        border-radius: 0.5rem;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 1px 3px rgba(0,0,0,0.12);
    }
    </style>
""", unsafe_allow_html=True)

def load_data():
    """ØªÙ‡ÙŠØ¦Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©"""
    if "data" not in st.session_state:
        st.session_state.data = None
        st.session_state.filename = None
        st.session_state.target = None
        st.session_state.data_info = {
            'upload_time': None,
            'last_modified': None,
            'preprocessing_steps': [],
            'data_schema': None
        }

def validate_data(df):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    issues = []
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
    missing_cols = df.columns[df.isnull().any()].tolist()
    if missing_cols:
        issues.append(f"Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {', '.join(missing_cols)}")
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ·Ø±ÙØ© ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
    for col in numeric_cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        outliers = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))][col]
        if len(outliers) > 0:
            issues.append(f"Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ·Ø±ÙØ© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¹Ù…ÙˆØ¯ {col}: {len(outliers)} Ù‚ÙŠÙ…Ø©")
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙ†Ø§Ø³Ù‚ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    for col in df.columns:
        unique_values = df[col].nunique()
        if unique_values == 1:
            issues.append(f"Ø§Ù„Ø¹Ù…ÙˆØ¯ {col} ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ…Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·")
        elif unique_values == len(df) and df[col].dtype == 'object':
            issues.append(f"Ø§Ù„Ø¹Ù…ÙˆØ¯ {col} Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…Ø¹Ø±Ù ÙØ±ÙŠØ¯")
    
    return issues

def show_data_info(df):
    """Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    st.subheader("ğŸ“‹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    # Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ", f"{df.shape[0]:,}")
    with col2:
        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©", df.shape[1])
    with col3:
        missing = df.isna().sum().sum()
        st.metric("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©", f"{missing:,}")
    with col4:
        memory_usage = df.memory_usage(deep=True).sum() / 1024**2
        st.metric("Ø­Ø¬Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©", f"{memory_usage:.2f} MB")

    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    st.subheader("ğŸ“Š Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    dtypes_df = pd.DataFrame({
        'Ø§Ù„Ø¹Ù…ÙˆØ¯': df.columns,
        'Ø§Ù„Ù†ÙˆØ¹': df.dtypes.values,
        'Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©': df.isna().sum().values,
        'Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø©': [df[col].nunique() for col in df.columns],
        'Ø§Ù„Ø¹ÙŠÙ†Ø©': [str(df[col].iloc[0]) if not df[col].empty else '' for col in df.columns]
    })
    st.dataframe(dtypes_df, hide_index=True)

    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙˆØµÙÙŠØ©
    st.subheader("ğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙˆØµÙÙŠØ©")
    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
    if not numeric_cols.empty:
        stats_df = df[numeric_cols].describe()
        st.dataframe(stats_df)

def plot_distribution(df, column):
    """Ø±Ø³Ù… ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    if pd.api.types.is_numeric_dtype(df[column]):
        fig = px.histogram(
            df, x=column,
            title=f"ØªÙˆØ²ÙŠØ¹ {column}",
            template="simple_white",
            marginal="box"
        )
        fig.update_layout(
            showlegend=False,
            xaxis_title=column,
            yaxis_title="Ø§Ù„ØªÙƒØ±Ø§Ø±"
        )
    else:
        value_counts = df[column].value_counts()
        fig = px.bar(
            x=value_counts.index,
            y=value_counts.values,
            title=f"ØªÙˆØ²ÙŠØ¹ {column}",
            template="simple_white"
        )
        fig.update_layout(
            showlegend=False,
            xaxis_title=column,
            yaxis_title="Ø§Ù„Ø¹Ø¯Ø¯"
        )
    return fig

def save_data_info():
    """Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    if st.session_state.data is not None:
        st.session_state.data_info['upload_time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        st.session_state.data_info['last_modified'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        df = st.session_state.data
        schema = {
            'columns': {col: str(dtype) for col, dtype in df.dtypes.items()},
            'rows': len(df),
            'missing_values': df.isna().sum().to_dict(),
            'unique_values': {col: df[col].nunique() for col in df.columns}
        }
        st.session_state.data_info['data_schema'] = schema

def generate_synthetic_data():
    """ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§ØµØ·Ù†Ø§Ø¹ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
    st.subheader("ğŸ”„ Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§ØµØ·Ù†Ø§Ø¹ÙŠØ©")
    
    data_type = st.selectbox(
        "Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
        ["ØªØµÙ†ÙŠÙ", "Ø§Ù†Ø­Ø¯Ø§Ø±", "ØªØ¬Ù…ÙŠØ¹"]
    )
    
    n_samples = st.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª", min_value=100, max_value=10000, value=1000, step=100)
    n_features = st.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ø®ØµØ§Ø¦Øµ", min_value=2, max_value=20, value=5, step=1)
    
    if st.button("Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
        if data_type == "ØªØµÙ†ÙŠÙ":
            from sklearn.datasets import make_classification
            X, y = make_classification(
                n_samples=n_samples,
                n_features=n_features,
                n_redundant=1,
                n_informative=n_features-2,
                random_state=42,
                n_clusters_per_class=2
            )
            feature_names = [f"Ø®Ø§ØµÙŠØ©_{i+1}" for i in range(n_features)]
            df = pd.DataFrame(X, columns=feature_names)
            df['Ø§Ù„Ù‡Ø¯Ù'] = y
            
        elif data_type == "Ø§Ù†Ø­Ø¯Ø§Ø±":
            from sklearn.datasets import make_regression
            X, y = make_regression(
                n_samples=n_samples,
                n_features=n_features,
                noise=0.1,
                random_state=42
            )
            feature_names = [f"Ø®Ø§ØµÙŠØ©_{i+1}" for i in range(n_features)]
            df = pd.DataFrame(X, columns=feature_names)
            df['Ø§Ù„Ù‡Ø¯Ù'] = y
            
        else:  # ØªØ¬Ù…ÙŠØ¹
            from sklearn.datasets import make_blobs
            X, y = make_blobs(
                n_samples=n_samples,
                n_features=n_features,
                centers=3,
                random_state=42
            )
            feature_names = [f"Ø®Ø§ØµÙŠØ©_{i+1}" for i in range(n_features)]
            df = pd.DataFrame(X, columns=feature_names)
            df['Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©'] = y
        
        st.session_state.data = df
        st.session_state.filename = f"synthetic_data_{data_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        st.session_state.data_info['upload_time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        st.success("ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!")
        show_data_info(df)

# Ø§Ù„ØªØ®Ø·ÙŠØ· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
load_data()
st.title("ğŸ“Š Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

# Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
with st.sidebar:
    data_option = st.radio(
        "Ø§Ø®ØªØ± Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
        ["ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù", "Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ù…ÙˆØ°Ø¬ÙŠØ©"]
    )

if data_option == "ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù":
    uploaded_file = st.file_uploader(
        "Ø§Ø®ØªØ± Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
        type=['csv', 'xlsx', 'xls'],
        help="ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª CSV Ø£Ùˆ Excel"
    )
    
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            st.session_state.data = df
            st.session_state.filename = uploaded_file.name
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            issues = validate_data(df)
            if issues:
                st.warning("âš ï¸ ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
                for issue in issues:
                    st.write(f"- {issue}")
            
            # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            show_data_info(df)
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            st.subheader("ğŸ” Ø§Ø³ØªØ¹Ø±Ø§Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            n_rows = st.slider("Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…Ø¹Ø±ÙˆØ¶Ø©", 5, 100, 10)
            st.dataframe(df.head(n_rows))
            
            # ØªØ­Ù„ÙŠÙ„ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            st.subheader("ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ²ÙŠØ¹")
            selected_column = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù„Ù„ØªØ­Ù„ÙŠÙ„", df.columns)
            fig = plot_distribution(df, selected_column)
            st.plotly_chart(fig, use_container_width=True)
            
            # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            save_data_info()
            
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {str(e)}")
else:  # Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ù…ÙˆØ°Ø¬ÙŠØ©
    generate_synthetic_data()
