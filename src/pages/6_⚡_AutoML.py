from src.utils.rtl_utils import apply_arabic_config
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import optuna
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    mean_squared_error, mean_absolute_error, r2_score
)
import joblib
import json
from datetime import datetime
import os

# ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠ
apply_arabic_config(title="Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ", icon="âš¡")

def validate_data():
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªÙˆÙØ±Ù‡Ø§"""
    if "data" not in st.session_state:
        st.error("ğŸš« ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹ Ù…Ù† ØµÙØ­Ø© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!")
        return False
        
    df = st.session_state.data
    if df.empty:
        st.error("âŒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù…Ù„Ø© ÙØ§Ø±ØºØ©!")
        return False
        
    if df.isnull().any().any():
        st.warning("âš ï¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©. ÙŠØ±Ø¬Ù‰ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ Ø£ÙˆÙ„Ø§Ù‹!")
        return False
        
    return True

def create_model_directory():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹"""
    models_dir = "models"
    if not os.path.exists(models_dir):
        try:
            os.makedirs(models_dir)
        except Exception as e:
            st.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {str(e)}")
            return False
    return True

def create_classification_model(trial):
    """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ ØªØµÙ†ÙŠÙ Ù…Ø¹ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…Ø­Ø³Ù†Ø©"""
    model_type = trial.suggest_categorical('model_type', ['rf', 'xgb', 'lgb', 'catboost'])
    
    try:
        if model_type == 'rf':
            from sklearn.ensemble import RandomForestClassifier
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                'max_depth': trial.suggest_int('max_depth', 3, 15),
                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10)
            }
            return RandomForestClassifier(**params, random_state=42)
            
        elif model_type == 'xgb':
            import xgboost as xgb
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                'max_depth': trial.suggest_int('max_depth', 3, 15),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0)
            }
            return xgb.XGBClassifier(**params, random_state=42)
            
        elif model_type == 'lgb':
            import lightgbm as lgb
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                'max_depth': trial.suggest_int('max_depth', 3, 15),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                'num_leaves': trial.suggest_int('num_leaves', 20, 100),
                'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0)
            }
            return lgb.LGBMClassifier(**params, random_state=42)
            
        else:  # catboost
            from catboost import CatBoostClassifier
            params = {
                'iterations': trial.suggest_int('iterations', 50, 300),
                'depth': trial.suggest_int('depth', 3, 15),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True)
            }
            return CatBoostClassifier(**params, random_state=42, verbose=False)
            
    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ: {str(e)}")
        return None

def create_regression_model(trial):
    """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù†Ø­Ø¯Ø§Ø± Ù…Ø¹ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…Ø­Ø³Ù†Ø©"""
    model_type = trial.suggest_categorical('model_type', ['rf', 'xgb', 'lgb', 'catboost'])
    
    try:
        if model_type == 'rf':
            from sklearn.ensemble import RandomForestRegressor
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                'max_depth': trial.suggest_int('max_depth', 3, 15),
                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10)
            }
            return RandomForestRegressor(**params, random_state=42)
            
        elif model_type == 'xgb':
            import xgboost as xgb
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                'max_depth': trial.suggest_int('max_depth', 3, 15),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0)
            }
            return xgb.XGBRegressor(**params, random_state=42)
            
        elif model_type == 'lgb':
            import lightgbm as lgb
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                'max_depth': trial.suggest_int('max_depth', 3, 15),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                'num_leaves': trial.suggest_int('num_leaves', 20, 100),
                'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0)
            }
            return lgb.LGBMRegressor(**params, random_state=42)
            
        else:  # catboost
            from catboost import CatBoostRegressor
            params = {
                'iterations': trial.suggest_int('iterations', 50, 300),
                'depth': trial.suggest_int('depth', 3, 15),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True)
            }
            return CatBoostRegressor(**params, random_state=42, verbose=False)
            
    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±: {str(e)}")
        return None

def evaluate_model(model, X_test, y_test, problem_type):
    """ØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
    try:
        y_pred = model.predict(X_test)
        
        if problem_type == "classification":
            metrics = {
                'accuracy': accuracy_score(y_test, y_pred),
                'precision': precision_score(y_test, y_pred, average='weighted'),
                'recall': recall_score(y_test, y_pred, average='weighted'),
                'f1': f1_score(y_test, y_pred, average='weighted')
            }
        else:
            metrics = {
                'r2': r2_score(y_test, y_pred),
                'mse': mean_squared_error(y_test, y_pred),
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),
                'mae': mean_absolute_error(y_test, y_pred)
            }
            
        return metrics
        
    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {str(e)}")
        return None

def objective(trial, X_train, X_test, y_train, y_test, problem_type):
    """Ø¯Ø§Ù„Ø© Ø§Ù„Ù‡Ø¯Ù Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª"""
    try:
        model = optimize_hyperparameters(trial, X_train, y_train, problem_type)
        if model is None:
            return float('-inf')
            
        metrics = evaluate_model(model, X_test, y_test, problem_type)
        if metrics is None:
            return float('-inf')
            
        if problem_type == "classification":
            return metrics['f1']
        else:
            return metrics['r2']
            
    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙ†ÙÙŠØ° Ø¯Ø§Ù„Ø© Ø§Ù„Ù‡Ø¯Ù: {str(e)}")
        return float('-inf')

def optimize_hyperparameters(trial, X_train, y_train, problem_type):
    """ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Optuna"""
    try:
        if problem_type == "classification":
            model = create_classification_model(trial)
        else:
            model = create_regression_model(trial)
            
        model.fit(X_train, y_train)
        return model
        
    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª: {str(e)}")
        return None

def save_model(model, model_info):
    """Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ…Ø¹Ù„ÙˆÙ…Ø§ØªÙ‡"""
    try:
        # ØªØ­Ø¶ÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_name = f"{model_info['name']}_{timestamp}"
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        models_dir = "models"
        if not os.path.exists(models_dir):
            os.makedirs(models_dir)
        
        # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        model_path = os.path.join(models_dir, f"{model_name}.joblib")
        joblib.dump(model, model_path)
        
        # ØªØ­Ø¶ÙŠØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ÙØ¸
        save_info = {
            'name': model_info['name'],
            'type': model_info['type'],
            'parameters': model_info.get('parameters', {}),
            'metrics': model_info.get('metrics', {}),
            'feature_names': model_info.get('feature_names', []),
            'target_name': model_info.get('target_name', 'target'),
            'target_type': model_info.get('target_type', 'unknown'),
            'training_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'file_path': model_path
        }
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªÙˆÙØ±Ø©
        if 'target_values' in model_info and model_info['target_values'] is not None:
            save_info['target_values'] = [str(v) for v in model_info['target_values']]
            
        if 'target_statistics' in model_info:
            stats = model_info['target_statistics']
            save_info['target_statistics'] = {
                'mean': float(stats['mean']) if stats.get('mean') is not None else None,
                'std': float(stats['std']) if stats.get('std') is not None else None,
                'min': float(stats['min']) if stats.get('min') is not None else None,
                'max': float(stats['max']) if stats.get('max') is not None else None,
                'unique_values': int(stats['unique_values']) if 'unique_values' in stats else None,
                'is_numeric': bool(stats.get('is_numeric', False))
            }
        
        # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ù…Ù„Ù JSON
        info_path = model_path.replace('.joblib', '_info.json')
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(save_info, f, ensure_ascii=False, indent=2)
        
        return True, model_path
        
    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {str(e)}")
        return False, None

def save_target_info(target_name, data, problem_type):
    """Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù"""
    target_series = data[target_name]
    
    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    stats = {}
    is_numeric = pd.api.types.is_numeric_dtype(target_series)
    
    if is_numeric:
        stats = {
            'mean': float(target_series.mean()) if not pd.isna(target_series.mean()) else None,
            'std': float(target_series.std()) if not pd.isna(target_series.std()) else None,
            'min': float(target_series.min()) if not pd.isna(target_series.min()) else None,
            'max': float(target_series.max()) if not pd.isna(target_series.max()) else None,
            'unique_values': int(target_series.nunique()),
            'is_numeric': True
        }
    else:
        stats = {
            'mean': None,
            'std': None,
            'min': None,
            'max': None,
            'unique_values': int(target_series.nunique()),
            'is_numeric': False
        }
    
    target_info = {
        'name': target_name,
        'type': problem_type,
        'dtype': str(target_series.dtype),
        'target_statistics': stats,
        'values': list(map(str, target_series.unique())) if problem_type == 'classification' else None
    }
    
    st.session_state['target'] = target_name
    st.session_state['target_info'] = target_info
    return target_info

def load_target_info():
    """ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù"""
    if 'target_info' in st.session_state:
        return st.session_state['target_info']
    return None

def display_target_info(target_info):
    """Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù"""
    if target_info:
        st.write("### ğŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù")
        
        col1, col2 = st.columns(2)
        with col1:
            st.write("**Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:**", target_info['type'])
            st.write("**Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù:**", target_info['name'])
            st.write("**Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:**", target_info['dtype'])
            
        with col2:
            if target_info['target_statistics']['is_numeric']:
                st.write("**Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù:**")
                stats = target_info['target_statistics']
                st.write(f"- Ø§Ù„Ù…ØªÙˆØ³Ø·: {stats['mean']:.2f}")
                st.write(f"- Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {stats['std']:.2f}")
                st.write(f"- Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¯Ù†ÙŠØ§: {stats['min']:.2f}")
                st.write(f"- Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù„ÙŠØ§: {stats['max']:.2f}")
            
            if target_info['values'] is not None:
                st.write("**Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø©:**", len(target_info['values']))
                st.write("**Ø§Ù„ÙØ¦Ø§Øª:**", ", ".join(map(str, target_info['values'])))

class AutoMLOptimizer:
    """ÙØ¦Ø© Ù„ØªØ­Ø³ÙŠÙ† Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
    
    def __init__(self, X, y, problem_type, n_trials=50, test_size=0.2):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø³Ù† Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ"""
        self.X = X
        self.y = y
        self.problem_type = problem_type
        self.n_trials = n_trials
        self.test_size = test_size
        self.best_model = None
        self.best_params = None
        self.best_score = None
        self.best_metrics = None
        self.feature_importance = None
        self.training_history = []
        
    def prepare_data(self):
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
        try:
            X_train, X_test, y_train, y_test = train_test_split(
                self.X, self.y, 
                test_size=self.test_size, 
                random_state=42
            )
            return X_train, X_test, y_train, y_test
        except Exception as e:
            st.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return None, None, None, None
            
    def optimize(self):
        """ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        try:
            # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            X_train, X_test, y_train, y_test = self.prepare_data()
            if X_train is None:
                return False
                
            # Ø¥Ù†Ø´Ø§Ø¡ Ø¯Ø±Ø§Ø³Ø© Optuna
            study = optuna.create_study(
                direction="maximize",
                study_name="automl_optimization"
            )
            
            # ØªØ­Ø¯ÙŠØ« Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨
            def callback(study, trial):
                progress = len(study.trials) / self.n_trials
                progress_bar.progress(progress)
                status_text.text(f"Ø§Ù„ØªÙ‚Ø¯Ù…: {progress:.0%} - Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©: {study.best_value:.4f}")
                self.training_history.append({
                    'trial': len(study.trials),
                    'value': trial.value,
                    'best_value': study.best_value
                })
            
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            study.optimize(
                lambda trial: objective(trial, X_train, X_test, y_train, y_test, self.problem_type),
                n_trials=self.n_trials,
                callbacks=[callback],
                catch=(Exception,)
            )
            
            # Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ…Ø¹Ù„ÙˆÙ…Ø§ØªÙ‡
            self.best_params = study.best_params
            self.best_score = study.best_value
            
            # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬
            if self.problem_type == "classification":
                self.best_model = create_classification_model(study.best_trial)
            else:
                self.best_model = create_regression_model(study.best_trial)
                
            if self.best_model is None:
                return False
                
            self.best_model.fit(X_train, y_train)
            self.best_metrics = evaluate_model(
                self.best_model, X_test, y_test, self.problem_type
            )
            
            # Ø­Ø³Ø§Ø¨ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
            if hasattr(self.best_model, 'feature_importances_'):
                self.feature_importance = pd.DataFrame({
                    'feature': self.X.columns,
                    'importance': self.best_model.feature_importances_
                }).sort_values('importance', ascending=False)
            
            progress_bar.progress(1.0)
            status_text.text("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ø³ÙŠÙ†!")
            return True
            
        except Exception as e:
            st.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ø³ÙŠÙ†: {str(e)}")
            return False
            
    def save_results(self):
        """Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ø³ÙŠÙ†"""
        if not self.best_model:
            st.error("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ø³Ù† Ù„Ù„Ø­ÙØ¸!")
            return False
            
        model_info = {
            'name': type(self.best_model).__name__,
            'type': self.problem_type,
            'parameters': self.best_params,
            'metrics': self.best_metrics,
            'feature_names': list(self.X.columns),
            'target_name': self.y.name if hasattr(self.y, 'name') else 'target',
            'target_values': list(self.y.unique()) if self.problem_type == 'classification' else None,
            'target_type': str(self.y.dtype),
            'training_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'n_trials': self.n_trials,
            'best_score': self.best_score,
            'target_statistics': {
                'mean': float(self.y.mean()) if pd.api.types.is_numeric_dtype(self.y) else None,
                'std': float(self.y.std()) if pd.api.types.is_numeric_dtype(self.y) else None,
                'min': float(self.y.min()) if pd.api.types.is_numeric_dtype(self.y) else None,
                'max': float(self.y.max()) if pd.api.types.is_numeric_dtype(self.y) else None,
                'unique_values': int(self.y.nunique()),
                'is_numeric': bool(pd.api.types.is_numeric_dtype(self.y))
            }
        }
        
        success, model_path = save_model(self.best_model, model_info)
        if success:
            st.success(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ: {model_path}")
            
            # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù ÙÙŠ session state
            st.session_state['target_info'] = {
                'name': model_info['target_name'],
                'type': model_info['type'],
                'values': model_info['target_values'],
                'statistics': model_info['target_statistics']
            }
            return True
        return False

# Ø§Ù„ØªØ®Ø·ÙŠØ· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
st.title("âš¡ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ")

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©
if 'data' not in st.session_state:
    st.error("âŒ ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ ÙˆØ¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹!")
    st.stop()

data = st.session_state.data

# Ø§Ø®ØªÙŠØ§Ø± Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù‡Ø¯Ù
target = None
if 'target' in st.session_state:
    target = st.session_state.target

available_columns = list(data.columns)
selected_target = st.selectbox(
    "ğŸ“Š Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù‡Ø¯Ù",
    options=available_columns,
    index=available_columns.index(target) if target in available_columns else 0,
    help="Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‡"
)

# ØªØ­Ø¯ÙŠØ« Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù‡Ø¯Ù ÙÙŠ session state
if selected_target != target:
    target = selected_target
    
    # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    if pd.api.types.is_numeric_dtype(data[target]):
        unique_values = data[target].nunique()
        if unique_values <= 10:
            default_problem_type = "classification"
        else:
            default_problem_type = "regression"
    else:
        default_problem_type = "classification"
    
    # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù
    target_info = save_target_info(target, data, default_problem_type)
    display_target_info(target_info)

# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
with st.sidebar:
    st.header("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†")
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø©
    n_trials = st.slider("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª", 10, 300, 100)
    test_size = st.slider("Ø­Ø¬Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±", 0.1, 0.9, 0.2)
    
    # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    if pd.api.types.is_numeric_dtype(data[target]):
        unique_values = data[target].nunique()
        if unique_values <= 10:  # ØªØµÙ†ÙŠÙ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø© Ù‚Ù„ÙŠÙ„
            default_problem_type = "classification"
        else:
            default_problem_type = "regression"
    else:
        default_problem_type = "classification"
    
    problem_type = st.selectbox(
        "Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©",
        ["classification", "regression"],
        index=0 if default_problem_type == "classification" else 1
    )
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ù…Ø¨ÙƒØ±
    use_early_stopping = st.checkbox("ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ù…Ø¨ÙƒØ±", True)
    if use_early_stopping:
        n_early_stopping = st.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ù„Ù„ØªÙˆÙ‚Ù Ø§Ù„Ù…Ø¨ÙƒØ±", 5, 50, 10)
    
    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    st.subheader("ğŸ¤– Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©")
    use_rf = st.checkbox("Random Forest", True)
    use_xgb = st.checkbox("XGBoost", True)
    use_lgb = st.checkbox("LightGBM", True)
    use_catboost = st.checkbox("CatBoost", True)
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
    with st.expander("ğŸ”§ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©"):
        pruning_enabled = st.checkbox("ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªÙ‚Ù„ÙŠÙ…", True)
        parallel_jobs = st.slider("Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©", -1, 8, -1)
        random_seed = st.number_input("Ø§Ù„Ø¨Ø°Ø±Ø© Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©", 0, 9999, 42)

try:
    X = data.drop(columns=[target])
    y = data[target]

    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø³Ù† AutoML
    optimizer = AutoMLOptimizer(
        X, y, problem_type, n_trials=n_trials, test_size=test_size
    )
    
    # Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ø³ÙŠÙ†
    if st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ø³ÙŠÙ†", type="primary"):
        success = optimizer.optimize()
        if success:
            # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù
            optimizer.save_results()
            
            # Ø­ÙØ¸ Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù ÙÙŠ session state
            st.session_state['target'] = target
            st.session_state['target_column'] = target
            
            # Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ù†Ø¬Ø§Ø­
            st.success(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­ Ù…Ø¹ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù: {target}")
            
            # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù
            if 'target_info' in st.session_state:
                st.write("### ğŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù")
                target_info = st.session_state['target_info']
                
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:**", target_info['type'])
                    st.write("**Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù:**", target_info['name'])
                
                with col2:
                    if target_info['statistics']['is_numeric']:
                        st.write("**Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù:**")
                        st.write(f"- Ø§Ù„Ù…ØªÙˆØ³Ø·: {target_info['statistics']['mean']:.2f}")
                        st.write(f"- Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {target_info['statistics']['std']:.2f}")
                        st.write(f"- Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¯Ù†ÙŠØ§: {target_info['statistics']['min']:.2f}")
                        st.write(f"- Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù„ÙŠØ§: {target_info['statistics']['max']:.2f}")
                    
                    if target_info['values'] is not None:
                        st.write("**Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø©:**", len(target_info['values']))
                        st.write("**Ø§Ù„ÙØ¦Ø§Øª:**", ", ".join(map(str, target_info['values'])))

except Exception as e:
    st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
    st.stop()
