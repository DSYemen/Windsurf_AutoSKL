from src.utils.rtl_utils import apply_arabic_config
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    mean_squared_error, mean_absolute_error, r2_score,
    confusion_matrix, roc_curve, auc, silhouette_score, calinski_harabasz_score, davies_bouldin_score
)
import joblib
import json
import os
from datetime import datetime
from sklearn.metrics import precision_recall_curve, classification_report

# Ø¯ÙˆØ§Ù„ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
def plot_confusion_matrix(cm, labels=None):
    """Ø±Ø³Ù… Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ"""
    if labels is None:
        labels = ['0', '1']
    
    fig = go.Figure(data=go.Heatmap(
        z=cm,
        x=labels,
        y=labels,
        colorscale='RdBu',
        text=cm,
        texttemplate="%{text}",
        textfont={"size": 16},
        hoverongaps=False
    ))
    
    fig.update_layout(
        title="Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ",
        xaxis_title="Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª",
        yaxis_title="Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©",
        width=600,
        height=600
    )
    
    return fig

def plot_roc_curve(y_true, y_prob):
    """Ø±Ø³Ù… Ù…Ù†Ø­Ù†Ù‰ ROC"""
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    roc_auc = auc(fpr, tpr)
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=fpr, y=tpr,
        mode='lines',
        name=f'ROC (AUC = {roc_auc:.3f})'
    ))
    
    fig.add_trace(go.Scatter(
        x=[0, 1], y=[0, 1],
        mode='lines',
        name='Random',
        line=dict(dash='dash', color='gray')
    ))
    
    fig.update_layout(
        title='Ù…Ù†Ø­Ù†Ù‰ ROC',
        xaxis_title='Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª Ø§Ù„Ø®Ø§Ø·Ø¦Ø©',
        yaxis_title='Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©',
        width=700,
        height=500
    )
    
    return fig

def plot_precision_recall_curve(y_true, y_prob):
    """Ø±Ø³Ù… Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø¯Ù‚Ø©-Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹"""
    precision, recall, _ = precision_recall_curve(y_true, y_prob)

    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=recall, y=precision,
        name='Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø¯Ù‚Ø©-Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹',
        mode='lines'
    ))

    fig.update_layout(
        title='Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø¯Ù‚Ø©-Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹',
        xaxis_title='Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹',
        yaxis_title='Ø§Ù„Ø¯Ù‚Ø©',
        width=700,
        height=500,
        hovermode='closest'
    )
    return fig

def plot_residuals(y_true, y_pred):
    """Ø±Ø³Ù… Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ"""
    residuals = y_true - y_pred
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=y_pred,
        y=residuals,
        mode='markers',
        marker=dict(
            size=8,
            color='blue',
            opacity=0.6
        ),
        name='Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ'
    ))
    
    fig.add_hline(y=0, line_dash="dash", line_color="red")
    
    fig.update_layout(
        title='Ù…Ø®Ø·Ø· Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ',
        xaxis_title='Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§',
        yaxis_title='Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ',
        width=700,
        height=500,
        showlegend=True
    )
    
    return fig

def plot_actual_vs_predicted(y_true, y_pred):
    """Ø±Ø³Ù… Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§"""
    fig = go.Figure()
    
    # Ø¥Ø¶Ø§ÙØ© Ù†Ù‚Ø§Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    fig.add_trace(go.Scatter(
        x=y_true,
        y=y_pred,
        mode='markers',
        marker=dict(
            size=8,
            color='blue',
            opacity=0.6
        ),
        name='Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª'
    ))
    
    # Ø¥Ø¶Ø§ÙØ© Ø®Ø· Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ
    min_val = min(min(y_true), min(y_pred))
    max_val = max(max(y_true), max(y_pred))
    fig.add_trace(go.Scatter(
        x=[min_val, max_val],
        y=[min_val, max_val],
        mode='lines',
        line=dict(color='red', dash='dash'),
        name='Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ'
    ))
    
    fig.update_layout(
        title='Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§',
        xaxis_title='Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©',
        yaxis_title='Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§',
        width=700,
        height=500,
        showlegend=True
    )
    
    return fig

def plot_feature_importance(model, feature_names):
    """Ø±Ø³Ù… Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª"""
    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
    if hasattr(model, 'feature_importances_'):
        importance = model.feature_importances_
    elif hasattr(model, 'coef_'):
        importance = np.abs(model.coef_[0]) if len(model.coef_.shape) > 1 else np.abs(model.coef_)
    else:
        return None
    
    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©
    feature_importance = pd.DataFrame({
        'feature': feature_names,
        'importance': importance
    })
    feature_importance = feature_importance.sort_values('importance', ascending=True)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
    fig = go.Figure()
    fig.add_trace(go.Bar(
        y=feature_importance['feature'],
        x=feature_importance['importance'],
        orientation='h',
        marker_color='blue'
    ))
    
    fig.update_layout(
        title='Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª',
        xaxis_title='Ø§Ù„Ø£Ù‡Ù…ÙŠØ©',
        yaxis_title='Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª',
        width=800,
        height=max(400, len(feature_names) * 25),
        showlegend=False
    )
    
    return fig

# ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠ
apply_arabic_config(title="ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", icon="ğŸ“Š")

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
def load_model_and_data():
    try:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ø´Ø·
        if 'active_model' not in st.session_state:
            st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹ Ù…Ù† ØµÙØ­Ø© Ø³Ø¬Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬")
            if st.button("ğŸ“š Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø³Ø¬Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"):
                st.switch_page("pages/7_ğŸ“š_Model_Registry.py")
            return None, None, None
            
        active_model = st.session_state.active_model
        model_path = active_model['path']
        
        if not os.path.exists(model_path):
            st.error("âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø¯Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
            return None, None, None
            
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ…Ø¹Ù„ÙˆÙ…Ø§ØªÙ‡
        try:
            model = joblib.load(model_path)
            model_info = active_model['info']
        except Exception as e:
            st.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {str(e)}")
            return None, None, None
            
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if 'data' not in st.session_state:
            st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹ Ù…Ù† ØµÙØ­Ø© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            if st.button("ğŸ“Š Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
                st.switch_page("pages/1_ğŸ“Š_Data_Management.py")
            return None, None, None
            
        df = st.session_state.data
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        required_features = model_info.get('features', [])
        if not required_features:
            required_features = model_info.get('feature_names', [])
            
        if not all(col in df.columns for col in required_features):
            st.error("âŒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù…Ù„Ø© Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬")
            st.write("Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:", ", ".join(required_features))
            st.write("Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©:", ", ".join(df.columns))
            return None, None, None
            
        return model, model_info, df
        
    except Exception as e:
        st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
        return None, None, None

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
model, model_info, df = load_model_and_data()

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
if model is not None and model_info is not None and df is not None and not df.empty:
    # ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù†Ù…Ø·
    st.markdown("""
        <style>
        .main { padding: 0rem 1rem; }
        .metric-card {
            background-color: #f8f9fa;
            padding: 1rem;
            border-radius: 0.5rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0,0,0,0.12);
        }
        .stAlert {
            padding: 1rem;
            margin-bottom: 1rem;
            border-radius: 0.5rem;
        }
        </style>
    """, unsafe_allow_html=True)

    # Ø§Ù„ØªØ®Ø·ÙŠØ· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    st.title("ğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")

    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªÙ‚ÙŠÙŠÙ…
    features = model_info.get('features', [])
    if not features:
        features = model_info.get('feature_names', [])
        
    X = df[features]
    target = model_info.get('target', '')
    if not target:
        target = model_info.get('target_name', '')
        
    if target in df.columns:
        y_true = df[target]
    else:
        st.warning("âš ï¸ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù‡Ø¯Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        y_true = None

    # Ø§Ù„ØªÙ†Ø¨Ø¤
    if y_true is not None:
        y_pred = model.predict(X)

        # Ø­Ø³Ø§Ø¨ ÙˆØ¹Ø±Ø¶ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„ØªØ¹Ù„Ù…
        model_type = model_info.get('type', '').lower()
        
        if model_type == 'ØªØµÙ†ÙŠÙ' or model_type == 'classification':
            # Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªØµÙ†ÙŠÙ
            metrics = {
                'Ø§Ù„Ø¯Ù‚Ø©': accuracy_score(y_true, y_pred),
                'Ø§Ù„Ø¶Ø¨Ø·': precision_score(y_true, y_pred, average='weighted'),
                'Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹': recall_score(y_true, y_pred, average='weighted'),
                'F1': f1_score(y_true, y_pred, average='weighted')
            }

            # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            st.write("### ğŸ“ˆ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡")
            cols = st.columns(len(metrics))
            for col, (metric_name, value) in zip(cols, metrics.items()):
                col.metric(metric_name, f"{value:.4f}")

            # Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ
            cm = confusion_matrix(y_true, y_pred)
            st.plotly_chart(plot_confusion_matrix(cm), use_container_width=True)

            # Ù…Ù†Ø­Ù†ÙŠØ§Øª ROC Ùˆ Precision-Recall Ù„Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠ
            if len(np.unique(y_true)) == 2 and hasattr(model, 'predict_proba'):
                y_prob = model.predict_proba(X)[:, 1]
                col1, col2 = st.columns(2)
                with col1:
                    st.plotly_chart(plot_roc_curve(y_true, y_prob), use_container_width=True)
                with col2:
                    st.plotly_chart(plot_precision_recall_curve(y_true, y_prob), use_container_width=True)

            # ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ
            st.write("### ğŸ“‘ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ")
            report = classification_report(y_true, y_pred, output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            st.dataframe(report_df)
            
        elif model_type == 'Ø§Ù†Ø­Ø¯Ø§Ø±' or model_type == 'regression':
            # Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±
            metrics = {
                'RÂ²': r2_score(y_true, y_pred),
                'MSE': mean_squared_error(y_true, y_pred),
                'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
                'MAE': mean_absolute_error(y_true, y_pred)
            }

            # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            st.write("### ğŸ“ˆ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡")
            cols = st.columns(len(metrics))
            for col, (metric_name, value) in zip(cols, metrics.items()):
                col.metric(metric_name, f"{value:.4f}")

            # Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„
            col1, col2 = st.columns(2)
            with col1:
                st.plotly_chart(plot_actual_vs_predicted(y_true, y_pred), use_container_width=True)
            with col2:
                st.plotly_chart(plot_residuals(y_true, y_pred), use_container_width=True)
                
        elif model_type == 'ØªØ¬Ù…ÙŠØ¹' or model_type == 'clustering':
            from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
            
            # Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªØ¬Ù…ÙŠØ¹
            try:
                metrics = {
                    'Ù…Ø¹Ø§Ù…Ù„ Ø³ÙŠÙ„ÙˆÙŠØª': silhouette_score(X, y_pred),
                    'Ù…Ø¹Ø§Ù…Ù„ ÙƒØ§Ù„ÙŠÙ†Ø³ÙƒÙŠ-Ù‡Ø§Ø±Ø¨Ø§Ø²': calinski_harabasz_score(X, y_pred),
                    'Ù…Ø¹Ø§Ù…Ù„ Ø¯ÙŠÙÙŠØ²-Ø¨ÙˆÙ„Ø¯Ù†': davies_bouldin_score(X, y_pred)
                }
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªØ¬Ù…ÙŠØ¹: {str(e)}")
                metrics = {}

            if metrics:
                # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
                st.write("### ğŸ“ˆ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡")
                cols = st.columns(len(metrics))
                for col, (metric_name, value) in zip(cols, metrics.items()):
                    col.metric(metric_name, f"{value:.4f}")

            # Ø¹Ø±Ø¶ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª
            st.write("### ğŸ¯ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª")
            cluster_counts = pd.Series(y_pred).value_counts().sort_index()
            fig = go.Figure(data=[
                go.Bar(x=[f"Ù…Ø¬Ù…ÙˆØ¹Ø© {i}" for i in cluster_counts.index],
                      y=cluster_counts.values)
            ])
            fig.update_layout(
                title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù†Ù‚Ø§Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª",
                xaxis_title="Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©",
                yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù‚Ø§Ø·",
                width=700,
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
            
        else:
            st.error(f"âŒ Ù†ÙˆØ¹ Ø§Ù„ØªØ¹Ù„Ù… ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ: {model_type}")
            st.stop()

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ (Ù„Ù„ØªØµÙ†ÙŠÙ ÙˆØ§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± ÙÙ‚Ø·)
        if model_type in ['ØªØµÙ†ÙŠÙ', 'classification', 'Ø§Ù†Ø­Ø¯Ø§Ø±', 'regression']:
            st.write("### ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡")
            error_df = pd.DataFrame({
                'Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©': y_true,
                'Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§': y_pred,
                'Ø§Ù„Ø®Ø·Ø£': np.abs(y_true - y_pred) if model_type in ['Ø§Ù†Ø­Ø¯Ø§Ø±', 'regression'] else y_true != y_pred
            })
            error_df = error_df.sort_values('Ø§Ù„Ø®Ø·Ø£', ascending=False).head(10)
            st.dataframe(error_df)

        # Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹)
        if hasattr(model, 'feature_importances_') or hasattr(model, 'coef_'):
            st.write("### ğŸ¯ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª")
            feature_importance_fig = plot_feature_importance(model, features)
            if feature_importance_fig:
                st.plotly_chart(feature_importance_fig, use_container_width=True)

        # ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        if st.button("ğŸ“¥ ØªØµØ¯ÙŠØ± Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…"):
            evaluation_results = {
                'model_info': model_info,
                'metrics': metrics,
                'evaluation_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'error_analysis': error_df.to_dict()
            }

            results_path = os.path.join(
                "models",
                f"evaluation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            )

            with open(results_path, 'w', encoding='utf-8') as f:
                json.dump(evaluation_results, f, ensure_ascii=False, indent=4)

            st.success(f"âœ… ØªÙ… Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙÙŠ: {results_path}")
